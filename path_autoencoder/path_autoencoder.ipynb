{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "cm = 1/2.54\n",
    "\n",
    "# force GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.src.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.src.layers import SimpleRNN, LSTM, Dense, Dropout, Bidirectional, Embedding, Input, RepeatVector, TimeDistributed, Reshape\n",
    "from keras import Sequential, Model\n",
    "from keras.losses import CategoricalCrossentropy, CategoricalFocalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/home/jrosendahl/datasets/cadets/sequences_export_benign_filetypes_path_ts/'\n",
    "experiment_name = 'path_autoencoder'\n",
    "\n",
    "checkpoint_path = f'saves/{experiment_name}'\n",
    "log_path = f'{checkpoint_path}/log.csv'\n",
    "history_path = f'{checkpoint_path}/history.npy'\n",
    "\n",
    "# ensure directory exists\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded: 50000\n",
      "Files loaded: 100000\n",
      "Files loaded: 150000\n",
      "Files loaded: 200000\n",
      "Files loaded: 215150\n",
      "len(X_train)=8161337\n",
      "vocab_size=79\n",
      "longest_path=167\n",
      "mean_length=16.771043273914557\n"
     ]
    }
   ],
   "source": [
    "# load data, build vocabulary\n",
    "\n",
    "vocab = set()\n",
    "X_train = []\n",
    "longest_path = 0\n",
    "mean_length = 0\n",
    "\n",
    "files_loaded = 0\n",
    "\n",
    "for filename in os.listdir(data_directory):\n",
    "    with open(os.path.join(data_directory, filename), 'r') as f:\n",
    "        files_loaded += 1\n",
    "        if files_loaded % 50000 == 0:\n",
    "            print(f\"Files loaded: {files_loaded}\")\n",
    "\n",
    "        for line in f:\n",
    "            line = line.split(',')\n",
    "            path1 = line[4]\n",
    "            path2 = line[5]\n",
    "            if path1 == 'None':\n",
    "                path1 = ''\n",
    "            if path2 == 'None':\n",
    "                path2 = ''\n",
    "\n",
    "            # add all characters to the vocabulary\n",
    "            vocab.update(path1)\n",
    "            vocab.update(path2)\n",
    "\n",
    "            longest_path = max(longest_path, len(path1))\n",
    "            longest_path = max(longest_path, len(path2))\n",
    "\n",
    "            if path1 != '':\n",
    "                X_train.append(path1)\n",
    "                mean_length += len(path1)\n",
    "            if path2 != '':\n",
    "                X_train.append(path2)\n",
    "                mean_length += len(path2)\n",
    "\n",
    "mean_length /= len(X_train)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "char_to_idx = {char: idx+1 for idx, char in enumerate(vocab)}\n",
    "# add padding character\n",
    "char_to_idx[''] = 0\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "print(f\"Files loaded: {files_loaded}\")\n",
    "print(f'{len(X_train)=}')\n",
    "print(f'{vocab_size=}')\n",
    "print(f'{longest_path=}')\n",
    "print(f'{mean_length=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_paths_optimized(X_train, char_to_idx, fixed_length):\n",
    "    # Initialize the array with zeros (for padding)\n",
    "    encoded_array = np.zeros((len(X_train), fixed_length), dtype=int)\n",
    "\n",
    "    # Iterate over each path and fill the appropriate positions in the array\n",
    "    for i, path in enumerate(X_train):\n",
    "        # Convert path to indices and fill in the array up to the fixed length\n",
    "        path_indices = [char_to_idx[char] for char in path[:fixed_length]]  # Truncate to fixed_length\n",
    "        assert path_indices is not None\n",
    "        encoded_array[i, :len(path_indices)] = path_indices  # Place indices in the array\n",
    "\n",
    "    return encoded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = encode_paths_optimized(X_train, char_to_idx, fixed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vectorized.shape=(8161337, 50)\n",
      "X_train_vectorized[0]=array([20, 31, 45, 73, 20, 54, 22,  5, 20, 75, 51, 11,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_train_vectorized.shape=}')\n",
    "print(f'{X_train_vectorized[0]=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_28 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_16 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m5,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,064</span> (422.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m108,064\u001b[0m (422.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,064</span> (422.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m108,064\u001b[0m (422.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,320</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_16 (\u001b[38;5;33mRepeatVector\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │        \u001b[38;5;34m10,320\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,248</span> (434.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,248\u001b[0m (434.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,248</span> (434.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,248\u001b[0m (434.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">108,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">111,248</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_28 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m108,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │       \u001b[38;5;34m111,248\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">219,312</span> (856.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m219,312\u001b[0m (856.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">219,312</span> (856.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m219,312\u001b[0m (856.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 32\n",
    "expand_dim = 64\n",
    "recurrent_dim = 128\n",
    "\n",
    "\n",
    "encoder_input = Input(shape=(fixed_length,))\n",
    "x = Embedding(input_dim=vocab_size+1, output_dim=expand_dim)(encoder_input)\n",
    "x = LSTM(recurrent_dim)(x)\n",
    "encoder_output = Dense(latent_dim, activation='relu')(x)\n",
    "\n",
    "# Create the encoder model\n",
    "encoder = Model(encoder_input, encoder_output, name='encoder')\n",
    "\n",
    "# Decoder definition\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "x = Dense(expand_dim, activation='relu')(decoder_input)\n",
    "x = RepeatVector(fixed_length)(x)\n",
    "x = LSTM(recurrent_dim, return_sequences=True)(x)\n",
    "decoder_output = TimeDistributed(Dense(vocab_size+1, activation='softmax'))(x)\n",
    "\n",
    "# Create the decoder model\n",
    "decoder = Model(decoder_input, decoder_output, name='decoder')\n",
    "\n",
    "# Autoencoder definition\n",
    "autoencoder_input = encoder_input\n",
    "encoded_sequence = encoder(autoencoder_input)\n",
    "decoded_sequence = decoder(encoded_sequence)\n",
    "\n",
    "# Create the autoencoder model by combining encoder and decoder\n",
    "autoencoder = Model(autoencoder_input, decoded_sequence, name='autoencoder')\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summaries\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModels(Callback):\n",
    "    def __init__(self, checkpoint_path, encoder, decoder, monitor='val_loss', mode='min', save_best_only=True):\n",
    "        super(SaveBestModels, self).__init__()\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best = None\n",
    "\n",
    "        if self.mode == 'min':\n",
    "            self.best = float('inf')\n",
    "        elif self.mode == 'max':\n",
    "            self.best = float('-inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "\n",
    "        if self.mode == 'min' and current < self.best:\n",
    "            print(f\"\\nEpoch {epoch + 1}: {self.monitor} improved from {self.best} to {current}. Saving models.\")\n",
    "            self.best = current\n",
    "            self.encoder.save(os.path.join(self.checkpoint_path, 'encoder.keras'))\n",
    "            self.decoder.save(os.path.join(self.checkpoint_path, 'decoder.keras'))\n",
    "\n",
    "        elif self.mode == 'max' and current > self.best:\n",
    "            print(f\"\\nEpoch {epoch + 1}: {self.monitor} improved from {self.best} to {current}. Saving models.\")\n",
    "            self.best = current\n",
    "            self.encoder.save(os.path.join(self.checkpoint_path, 'encoder.keras'))\n",
    "            self.decoder.save(os.path.join(self.checkpoint_path, 'decoder.keras'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    SaveBestModels(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        patience=9,\n",
    "        restore_best_weights=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        patience=3,\n",
    "        factor=0.5,\n",
    "        verbose=1\n",
    "    ),\n",
    "    CSVLogger(log_path),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, data, batch_size, fixed_length, vocab_size, shuffle=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.fixed_length = fixed_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.data))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indices for the batch\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate data for the batch\n",
    "        X_batch = self.__data_generation(batch_indices)\n",
    "\n",
    "        # Since it's an autoencoder, the target data is the same as the input data\n",
    "        return X_batch, X_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indices after each epoch if shuffle is True\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, batch_indices):\n",
    "        # Generate data for a batch of given indices\n",
    "        # This is where you can customize your data loading and processing\n",
    "        batch_data = [self.data[i] for i in batch_indices]\n",
    "\n",
    "        # Convert the batch data to a numpy array (or whatever format is needed)\n",
    "        X_batch = np.array(batch_data)\n",
    "\n",
    "        # Ensure the data is padded or truncated to fixed_length\n",
    "        X_batch = np.array([np.pad(x, (0, max(0, self.fixed_length - len(x))), constant_values=0)[:self.fixed_length] for x in X_batch])\n",
    "\n",
    "        return X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data 85, 10, 5\n",
    "train_split = 0.85\n",
    "val_split = 0.1\n",
    "test_split = 0.05\n",
    "\n",
    "train_size = int(len(X_train_vectorized) * train_split)\n",
    "val_size = int(len(X_train_vectorized) * val_split)\n",
    "test_size = int(len(X_train_vectorized) * test_split)\n",
    "\n",
    "X_train_split = X_train_vectorized[:train_size]\n",
    "X_val_split = X_train_vectorized[train_size:train_size+val_size]\n",
    "X_test_split = X_train_vectorized[train_size+val_size:]\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_generator = DataGenerator(X_train_split, batch_size, fixed_length, vocab_size)\n",
    "val_generator = DataGenerator(X_val_split, batch_size, fixed_length, vocab_size)\n",
    "test_generator = DataGenerator(X_test_split, batch_size, fixed_length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train autoencoder\n",
    "history = autoencoder.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=200, \n",
    "    callbacks=callbacks  # Include the custom callback\n",
    ")\n",
    "\n",
    "# save history\n",
    "with open(history_path, 'wb') as f:\n",
    "    np.save(f, history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = [\n",
    "    '/home/jrosendahl/benign_filetypes_path_ts',\n",
    "    '/home/jrosendahl/malicious_filetypes_path_ts',\n",
    "]\n",
    "\n",
    "\n",
    "# encode test_path with encoder\n",
    "# def encode_paths_optimized(X_train, char_to_idx, fixed_length):\n",
    "\n",
    "res = encode_paths_optimized(test_paths, char_to_idx, fixed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76 75 73 69 32 76 38  8 73 63 32 43 50 35 75 71 76 18 32 43 21 59 43 79\n",
      "  12 21 71 32 68 58 33 32 63 79 33 35 68 75 79 68 63  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [76 75 73 69 32 76 38  8 73 63 32 43 50 35 75 71 76 69 35 71 21 16 21 73\n",
      "   2 63 79 12 21 71 32 68 58 33 32 63 79 33 35 68 75 79 68 63  0  0  0  0\n",
      "   0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n"
     ]
    }
   ],
   "source": [
    "transformed_paths = encoder.predict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.3506565  0.         1.9430115  0.90554965 0.         1.2480431\n",
      "  1.1075732  0.86714685 1.1801691  1.6789837  0.         0.21041426\n",
      "  0.48095703 0.6075881  0.         0.        ]\n",
      " [3.2347128  0.         2.0553188  0.8587782  0.         1.1337669\n",
      "  0.9993465  1.0855874  1.3916743  1.645171   0.         0.50308764\n",
      "  0.2815776  0.2886235  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(transformed_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step\n",
      "[[[9.86465878e-08 1.85292840e-11 2.39448905e-08 ... 5.92557503e-10\n",
      "   3.42792879e-14 1.74338202e-12]\n",
      "  [3.91157255e-06 2.19447682e-09 6.65792048e-01 ... 2.25916665e-06\n",
      "   1.26040733e-10 1.88759168e-06]\n",
      "  [3.25647271e-14 1.20814097e-14 2.76604289e-04 ... 2.91658191e-12\n",
      "   4.51178960e-15 2.17608727e-14]\n",
      "  ...\n",
      "  [9.99788821e-01 4.95611253e-17 1.35953965e-12 ... 1.58455538e-13\n",
      "   5.58775497e-08 1.12880295e-14]\n",
      "  [9.99992847e-01 2.20202634e-18 1.16357075e-15 ... 3.19679255e-15\n",
      "   8.51536008e-10 8.27269869e-16]\n",
      "  [9.99994516e-01 5.00004831e-19 1.65936920e-15 ... 4.22274247e-16\n",
      "   1.43458767e-09 8.64706978e-16]]\n",
      "\n",
      " [[1.49066253e-07 2.97048497e-11 5.29830935e-08 ... 7.54988072e-10\n",
      "   6.00212629e-14 1.41899036e-12]\n",
      "  [1.97131999e-06 1.26027910e-09 8.31270576e-01 ... 1.23633049e-06\n",
      "   1.71489239e-10 2.78861364e-07]\n",
      "  [1.69728272e-13 5.58977913e-14 5.67151094e-03 ... 2.32912162e-11\n",
      "   8.02207693e-14 4.02713670e-13]\n",
      "  ...\n",
      "  [9.98809934e-01 7.02600489e-16 6.51416490e-11 ... 9.14310294e-13\n",
      "   4.10462826e-06 4.11317612e-11]\n",
      "  [9.98108506e-01 3.34854173e-16 5.62240636e-11 ... 9.92314737e-13\n",
      "   1.23291898e-06 9.66287597e-13]\n",
      "  [9.99667048e-01 2.53155860e-16 2.15050999e-13 ... 5.49589942e-13\n",
      "   1.20549259e-08 1.96647796e-14]]]\n"
     ]
    }
   ],
   "source": [
    "reconstructed_paths = decoder.predict(transformed_paths)\n",
    "\n",
    "print(reconstructed_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform back to strings\n",
    "reconstructed_paths = np.argmax(reconstructed_paths, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_paths = [''.join([idx_to_char[idx] for idx in path]) for path in reconstructed_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/uom//uprre/aassssssssssssseettttttttttttt', '/uoc/parae/aaaasssssssseeeeetttttttttttttttt']\n"
     ]
    }
   ],
   "source": [
    "print(reconstructed_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load encoder, decoder models\n",
    "encoder = load_model(f'{checkpoint_path}/encoder.keras')\n",
    "decoder = load_model(f'{checkpoint_path}/decoder.keras')\n",
    "\n",
    "# build autoencoder model\n",
    "autoencoder_input = encoder.input\n",
    "encoded_sequence = encoder(autoencoder_input)\n",
    "decoded_sequence = decoder(encoded_sequence)\n",
    "autoencoder = Model(autoencoder_input, decoded_sequence, name='autoencoder')\n",
    "autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_path(path: str, char_to_idx: dict, fixed_length: int, encoder: Model):\n",
    "    \"take a path as a string, return the result from the encoder\"\n",
    "    path_indices = [char_to_idx[char] for char in path[:fixed_length]]\n",
    "    path_indices = np.array(path_indices)\n",
    "    path_indices = np.pad(path_indices, (0, max(0, fixed_length - len(path_indices))), constant_values=0)[:fixed_length]\n",
    "    path_indices = np.array([path_indices])\n",
    "    return encoder.predict(path_indices)\n",
    "\n",
    "def decode_path(encoded_path: np.ndarray, decoder: Model, idx_to_char: dict):\n",
    "    \"take the result from the encoder, return the decoded path\"\n",
    "    decoded_path = decoder.predict(encoded_path)\n",
    "    decoded_path = np.argmax(decoded_path, axis=2)\n",
    "    decoded_path = [''.join([idx_to_char[idx] for idx in path]) for path in decoded_path]\n",
    "    return decoded_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.19452104, 0.269752  , 0.        , 0.        , 0.        ,\n",
       "        0.        , 2.180835  , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01902695, 0.        , 0.        , 0.        ,\n",
       "        0.24062942, 2.0384183 , 0.06973484, 1.1193109 , 0.        ,\n",
       "        1.5873064 , 0.83516556, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.0387359 ,\n",
       "        0.        , 1.2860181 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = encode_path('/dev/null', char_to_idx, fixed_length, encoder)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['h5/-hh<<FxQ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = decode_path(test, decoder, idx_to_char)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  12/1594\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7017 - loss: 4.4755"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrosendahl/.virtualenvs/models/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1594/1594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6386 - loss: 5.1317\n",
      "Test result: [6.136971950531006, 0.5515469312667847]\n"
     ]
    }
   ],
   "source": [
    "# evaluate autoencoder on X_test\n",
    "test_generator = DataGenerator(X_test_split, batch_size, fixed_length, vocab_size, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_result = autoencoder.evaluate(test_generator)\n",
    "\n",
    "print(f'Test logg: {test_result[0]}\\nTest accuracy: {test_result[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
