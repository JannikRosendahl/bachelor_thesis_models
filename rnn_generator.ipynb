{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61787a020b38b130",
   "metadata": {},
   "source": [
    "inspiration: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783c2596f19bebe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:38:22.813440Z",
     "start_time": "2024-06-11T10:38:22.807875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 09:36:56.457320: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-12 09:36:57.302746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import pool\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.src.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.src.layers import SimpleRNN, Dense, Dropout\n",
    "from keras import Sequential, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0261796f9f9c755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:39:40.083613Z",
     "start_time": "2024-06-11T10:39:40.060621Z"
    }
   },
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    'dbname': 'cadets_e3',\n",
    "    'user': 'rosendahl',\n",
    "    'password': '',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "connection = None\n",
    "cursor = None\n",
    "\n",
    "def setup_connection():\n",
    "    global connection\n",
    "    global cursor\n",
    "    connection = psycopg2.connect(**db_config)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "def close_connection():\n",
    "    # Close the database connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "\n",
    "sequence_ids = None\n",
    "sequence_ids_training = None\n",
    "sequence_ids_validation = None\n",
    "\n",
    "labels = None\n",
    "no_labels = None\n",
    "\n",
    "features = None\n",
    "no_features = None\n",
    "\n",
    "def get_sequence_ids():\n",
    "    global sequence_ids\n",
    "    query = '''\n",
    "    select subject_uuid, exec\n",
    "    from sequence\n",
    "    where length <= 1000;\n",
    "    '''\n",
    "    cursor.execute(query)\n",
    "    sequence_ids = cursor.fetchall()\n",
    "    print(f'loaded {len(sequence_ids)} sequence ids')\n",
    "\n",
    "def split_sequence_ids(validation_split=0.2):\n",
    "    global sequence_ids\n",
    "    global sequence_ids_training\n",
    "    global sequence_ids_validation\n",
    "    np.random.shuffle(sequence_ids)\n",
    "    split_index = int(len(sequence_ids) * (1 - validation_split))\n",
    "    sequence_ids_training = sequence_ids[:split_index]\n",
    "    sequence_ids_validation = sequence_ids[split_index:]\n",
    "    print(f'training set: {len(sequence_ids_training)}')\n",
    "    print(f'validation set: {len(sequence_ids_validation)}')\n",
    "\n",
    "def get_labels():\n",
    "    global labels\n",
    "    global no_labels\n",
    "    query = '''\n",
    "    select distinct exec\n",
    "    from sequence;\n",
    "    '''\n",
    "    cursor.execute(query)\n",
    "    labels = [ x[0] for x in cursor.fetchall() ]\n",
    "    no_labels = len(labels)\n",
    "    print(f'found {no_labels} labels')\n",
    "    print(f'labels: {labels}')\n",
    "\n",
    "def get_features():\n",
    "    global features\n",
    "    global no_features\n",
    "    query = '''\n",
    "    select distinct e.type\n",
    "    from event e;\n",
    "    '''\n",
    "    cursor.execute(query)\n",
    "    features = [ x[0]for x in cursor.fetchall() ]\n",
    "    features.append('NONE')\n",
    "    no_features = len(features)\n",
    "    print(f'found {no_features} features')\n",
    "    print(f'features: {features}')\n",
    "\n",
    "def print_class_distribution():\n",
    "    query = '''\n",
    "    select exec, count(*) as count\n",
    "    from sequence\n",
    "    where length <= 1000\n",
    "    group by exec\n",
    "    order by count desc;\n",
    "    '''\n",
    "    cursor.execute(query)\n",
    "    data = cursor.fetchall()\n",
    "    data = { x[0]: x[1] for x in data }\n",
    "    print(f'class distribution: {data}')\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, sequence_ids, db_config, batch_size, shuffle=True, use_multiprocessing=True, workers=4):\n",
    "        \"\"\"\n",
    "        sequence_ids: list of tuples (subject_uuid, exec)\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            use_multiprocessing=use_multiprocessing,\n",
    "            workers=workers\n",
    "        )\n",
    "        self.db_config = db_config\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sequence_ids = sequence_ids\n",
    "        self.indexes = np.arange(len(self.sequence_ids))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Calculate the number of batches per epoch\n",
    "        return int(np.floor(len(self.sequence_ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # batch_data = [self.data[k] for k in indexes]\n",
    "        batch_data = []\n",
    "\n",
    "        # TODO: use connection pool or something comparable to allow reuse of connections/cursors\n",
    "        with psycopg2.connect(**db_config) as local_connection:\n",
    "            with local_connection.cursor() as local_cursor:\n",
    "                for k in indexes:\n",
    "                    subject_uuid, executable = self.sequence_ids[k]\n",
    "\n",
    "                    query = '''\n",
    "                    select e.type\n",
    "                    from event e\n",
    "                    where e.subject_uuid = %s\n",
    "                    and e.properties_map_exec = %s\n",
    "                    order by e.sequence_long;\n",
    "                    '''\n",
    "                    # result of this query is list of tuple (one item)\n",
    "                    local_cursor.execute(query, (subject_uuid, executable))\n",
    "                    data = local_cursor.fetchall()\n",
    "                    data = [x[0] for x in data]\n",
    "                    if len(data) > 1000:\n",
    "                        data = data[:1000]\n",
    "                    batch_data.append((executable, data))\n",
    "                    \"\"\"\n",
    "                    filename = f'/home/jrosendahl/datasets/cadets/sequences/{executable}_{subject_uuid}.csv'\n",
    "                    with open(filename, 'r') as f:\n",
    "                        data = f.readlines()\n",
    "                        data = [x.strip() for x in data]\n",
    "                        batch_data.append((executable, data))\n",
    "                    \"\"\"\n",
    "        X, y = self.__data_generation(batch_data)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Updates indexes after each epoch\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch_data):\n",
    "        # Generate data for one batch\n",
    "        X = []\n",
    "        y = []\n",
    "        # find max sequences length\n",
    "        max_len = 0\n",
    "        for executable, sequence_data in batch_data:\n",
    "            max_len = len(sequence_data) if len(sequence_data) > max_len else max_len \n",
    "        for executable, sequence_data in batch_data:\n",
    "            # Assuming the last column is the target variable\n",
    "            while len(sequence_data) < max_len:\n",
    "                sequence_data.append('NONE')\n",
    "            X.append(self.encode_data(sequence_data))\n",
    "            y.append(self.encode_label(executable))\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        return X, y\n",
    "\n",
    "    def encode_label(self, label):\n",
    "        label_index = np.unique(np.array(labels)).tolist().index(label)\n",
    "        one_hot = np.zeros(no_labels)\n",
    "        one_hot[label_index] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def encode_data(self, data):\n",
    "        seq_len = len(data)\n",
    "        new_data = np.zeros((seq_len, no_features))\n",
    "        for i, feature in enumerate(data):\n",
    "            new_data[i, features.index(feature)] = 1\n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed744d08a055578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:39:46.247469Z",
     "start_time": "2024-06-11T10:39:43.731004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 428875 sequence ids\n",
      "training set: 343100\n",
      "validation set: 85775\n",
      "found 135 labels\n",
      "labels: ['adjkerntz', 'alpine', 'anvil', 'atrun', 'awk', 'basename', 'bash', 'bounce', 'bzcat', 'bzip2', 'cat', 'chkgrp', 'chmod', 'chown', 'cleanup', 'cmp', 'cp', 'cron', 'csh', 'cut', 'date', 'dd', 'devd', 'df', 'dhclient', 'diff', 'dmesg', 'egrep', 'env', 'expr', 'find', 'fortune', 'getty', 'grep', 'head', 'hostname', 'id', 'ifconfig', 'imapd', 'inetd', 'init', 'ipfstat', 'ipfw', 'ipop3d', 'jot', 'kenv', 'kill', 'kldstat', 'less', 'limits', 'links', 'local', 'locale', 'locate.code', 'lockf', 'login', 'ls', 'lsof', 'lsvfs', 'mail', 'mail.local', 'mailwrapper', 'main', 'makewhatis', 'master', 'minions', 'mkdir', 'mktemp', 'mlock', 'mount', 'msgs', 'mv', 'nawk', 'netstat', 'newsyslog', 'nginx', 'nice', 'nohup', 'ntpd', 'pEja72mA', 'pfctl', 'php-fpm', 'pickup', 'ping', 'pkg', 'postmap', 'procstat', 'proxymap', 'ps', 'pw', 'pwait', 'pwd_mkdb', 'python2.7', 'qmgr', 'resizewin', 'rm', 'route', 'screen', 'sed', 'sendmail', 'sh', 'sleep', 'smtp', 'smtpd', 'sort', 'ssh', 'sshd', 'stat', 'stty', 'su', 'sudo', 'sysctl', 'syslogd', 'tail', 'tee', 'test', 'tmux-1002', 'top', 'touch', 'tr', 'trivial-rewrite', 'tty', 'uname', 'uniq', 'unlink', 'uptime', 'vi', 'vmstat', 'vUgefal', 'wc', 'wget', 'which', 'whoami', 'XIM', 'xz']\n",
      "found 32 features\n",
      "features: ['EVENT_ACCEPT', 'EVENT_ADD_OBJECT_ATTRIBUTE', 'EVENT_BIND', 'EVENT_CHANGE_PRINCIPAL', 'EVENT_CLOSE', 'EVENT_CONNECT', 'EVENT_CREATE_OBJECT', 'EVENT_EXECUTE', 'EVENT_EXIT', 'EVENT_FCNTL', 'EVENT_FLOWS_TO', 'EVENT_FORK', 'EVENT_LINK', 'EVENT_LOGIN', 'EVENT_LSEEK', 'EVENT_MMAP', 'EVENT_MODIFY_FILE_ATTRIBUTES', 'EVENT_MODIFY_PROCESS', 'EVENT_MPROTECT', 'EVENT_OPEN', 'EVENT_OTHER', 'EVENT_READ', 'EVENT_RECVFROM', 'EVENT_RECVMSG', 'EVENT_RENAME', 'EVENT_SENDMSG', 'EVENT_SENDTO', 'EVENT_SIGNAL', 'EVENT_TRUNCATE', 'EVENT_UNLINK', 'EVENT_WRITE', 'NONE']\n",
      "class distribution: {'bash': 159926, 'sleep': 61839, 'vmstat': 30877, 'sh': 23560, 'imapd': 18879, 'top': 15618, 'date': 15469, 'lsof': 15451, 'head': 15441, 'mv': 10940, 'cron': 10167, 'master': 8895, 'mlock': 7817, 'sshd': 5852, 'inetd': 4321, 'atrun': 3116, 'local': 2496, 'sysctl': 1567, 'dd': 1560, 'unlink': 1551, 'smtpd': 1398, 'proxymap': 1198, 'resizewin': 1167, 'fortune': 1166, 'cleanup': 1150, 'trivial-rewrite': 1107, 'alpine': 922, 'anvil': 866, 'netstat': 432, 'rm': 430, 'cat': 331, 'sendmail': 275, 'newsyslog': 272, 'mkdir': 239, 'find': 232, 'dmesg': 187, 'uptime': 184, 'wget': 180, 'pkg': 148, 'hostname': 134, 'adjkerntz': 132, 'wc': 99, 'dhclient': 98, 'route': 86, 'mktemp': 85, 'sudo': 72, 'ls': 61, 'grep': 58, 'ps': 58, 'awk': 57, 'cmp': 51, 'mailwrapper': 48, 'lockf': 48, 'egrep': 33, 'mail': 29, 'sort': 28, 'sed': 27, 'mount': 26, 'expr': 25, 'tty': 24, 'links': 18, 'kenv': 17, 'less': 16, 'bzcat': 13, 'nginx': 12, 'cp': 12, 'kill': 12, 'df': 12, 'bzip2': 12, 'chkgrp': 11, 'basename': 11, 'msgs': 11, 'tr': 10, 'csh': 9, 'uname': 9, 'ipfstat': 9, 'jot': 9, 'screen': 8, 'python2.7': 8, 'pfctl': 8, 'diff': 7, 'stat': 7, 'ping': 6, 'ipfw': 6, 'pickup': 6, 'su': 6, 'postmap': 5, 'tee': 5, 'env': 5, 'test': 5, 'nohup': 5, 'nawk': 5, 'vi': 4, 'uniq': 4, 'tail': 4, 'pw': 4, 'smtp': 4, 'bounce': 4, 'ifconfig': 4, 'stty': 3, 'limits': 3, 'ipop3d': 3, 'XIM': 3, 'login': 2, 'getty': 2, 'cut': 2, 'which': 2, 'pwd_mkdb': 2, 'procstat': 2, 'id': 2, 'kldstat': 2, 'tmux-1002': 2, 'minions': 2, 'init': 2, 'pwait': 1, 'pEja72mA': 1, 'nice': 1, 'main': 1, 'mail.local': 1, 'lsvfs': 1, 'ssh': 1, 'locale': 1, 'touch': 1, 'chown': 1, 'vUgefal': 1, 'chmod': 1, 'whoami': 1}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the data generator\n",
    "setup_connection()\n",
    "get_sequence_ids()\n",
    "split_sequence_ids()\n",
    "get_labels()\n",
    "get_features()\n",
    "\n",
    "print_class_distribution()\n",
    "\n",
    "training_generator = DataGenerator(sequence_ids_training, db_config, batch_size=32, shuffle=True, use_multiprocessing=True, workers=16)\n",
    "validation_generator = DataGenerator(sequence_ids_validation, db_config, batch_size=32, shuffle=True, use_multiprocessing=True, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ea60749a330234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:34:13.873226Z",
     "start_time": "2024-06-11T10:34:13.160549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 09:37:01.371903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9798 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2024-06-12 09:37:01.372649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9658 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,775</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m135\u001b[0m)            │         \u001b[38;5;34m8,775\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,495</span> (123.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,495\u001b[0m (123.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,495</span> (123.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,495\u001b[0m (123.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential(layers=[\n",
    "    Input(shape=(None, no_features)),\n",
    "    SimpleRNN(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(64, return_sequences=False),\n",
    "    Dense(no_labels, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d70c006285cd5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:39:19.189474Z",
     "start_time": "2024-06-11T10:39:19.156049Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "checkpoint_path = (\"/home/jrosendahl/sync/models/checkpoints\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f'{checkpoint_path}/rnn_generator.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_schedule = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1, \n",
    "    patience=3, \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:39:25.249634Z",
     "start_time": "2024-06-11T10:39:25.071108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718177825.450108  346636 service.cc:145] XLA service 0x9d87100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718177825.450180  346636 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "I0000 00:00:1718177825.450187  346636 service.cc:153]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-06-12 09:37:05.537432: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-12 09:37:05.868661: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    1/10721\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:59:33\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 4.9555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718177829.103967  346636 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 4383/10721\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m49:58\u001b[0m 473ms/step - accuracy: 0.3866 - loss: 2.4071"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=25,\n",
    "    callbacks=[early_stop, model_checkpoint],\n",
    ")\n",
    "\n",
    "# Don't forget to close the connection after training\n",
    "close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b63127-c144-4489-a42a-c9f167251832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"accuracy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
