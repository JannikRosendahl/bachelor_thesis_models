{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "cm = 1/2.54\n",
    "\n",
    "# force GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.src.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.src.layers import SimpleRNN, LSTM, Dense, Dropout, Bidirectional, Embedding, Input, RepeatVector, TimeDistributed, Reshape\n",
    "from keras import Sequential, Model\n",
    "from keras.losses import CategoricalCrossentropy, CategoricalFocalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/home/jrosendahl/datasets/cadets/sequences_export_benign_filetypes_path_ts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded: 50000\n",
      "Files loaded: 100000\n",
      "Files loaded: 150000\n",
      "Files loaded: 200000\n",
      "Files loaded: 215150\n",
      "len(X_train)=8161337\n",
      "vocab_size=79\n",
      "longest_path=167\n",
      "mean_length=16.771043273914557\n"
     ]
    }
   ],
   "source": [
    "# load data, build vocabulary\n",
    "\n",
    "vocab = set()\n",
    "X_train = []\n",
    "longest_path = 0\n",
    "mean_length = 0\n",
    "\n",
    "files_loaded = 0\n",
    "\n",
    "for filename in os.listdir(data_directory):\n",
    "    with open(os.path.join(data_directory, filename), 'r') as f:\n",
    "        files_loaded += 1\n",
    "        if files_loaded % 50000 == 0:\n",
    "            print(f\"Files loaded: {files_loaded}\")\n",
    "\n",
    "        for line in f:\n",
    "            line = line.split(',')\n",
    "            path1 = line[4]\n",
    "            path2 = line[5]\n",
    "            if path1 == 'None':\n",
    "                path1 = ''\n",
    "            if path2 == 'None':\n",
    "                path2 = ''\n",
    "\n",
    "            # add all characters to the vocabulary\n",
    "            vocab.update(path1)\n",
    "            vocab.update(path2)\n",
    "\n",
    "            longest_path = max(longest_path, len(path1))\n",
    "            longest_path = max(longest_path, len(path2))\n",
    "\n",
    "            if path1 != '':\n",
    "                X_train.append(path1)\n",
    "                mean_length += len(path1)\n",
    "            if path2 != '':\n",
    "                X_train.append(path2)\n",
    "                mean_length += len(path2)\n",
    "\n",
    "mean_length /= len(X_train)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "char_to_idx = {char: idx+1 for idx, char in enumerate(vocab)}\n",
    "# add padding character\n",
    "char_to_idx[''] = 0\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "print(f\"Files loaded: {files_loaded}\")\n",
    "print(f'{len(X_train)=}')\n",
    "print(f'{vocab_size=}')\n",
    "print(f'{longest_path=}')\n",
    "print(f'{mean_length=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_paths_optimized(X_train, char_to_idx, fixed_length):\n",
    "    # Initialize the array with zeros (for padding)\n",
    "    encoded_array = np.zeros((len(X_train), fixed_length), dtype=int)\n",
    "\n",
    "    # Iterate over each path and fill the appropriate positions in the array\n",
    "    for i, path in enumerate(X_train):\n",
    "        # Convert path to indices and fill in the array up to the fixed length\n",
    "        path_indices = [char_to_idx[char] for char in path[:fixed_length]]  # Truncate to fixed_length\n",
    "        assert path_indices is not None\n",
    "        encoded_array[i, :len(path_indices)] = path_indices  # Place indices in the array\n",
    "\n",
    "    return encoded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = encode_paths_optimized(X_train, char_to_idx, fixed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8161337, 50)\n",
      "[76  2 63  8 76 18 21 43 76 68 73 33  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vectorized.shape)\n",
    "print(X_train_vectorized[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,504</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │        \u001b[38;5;34m11,504\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,504</span> (44.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,504\u001b[0m (44.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,504</span> (44.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,504\u001b[0m (44.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m   974/204034\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:55\u001b[0m 20ms/step - accuracy: 0.7059 - loss: 1.5587"
     ]
    }
   ],
   "source": [
    "# autoencoder model, encoder and decoder\n",
    "# save encoder \n",
    "\n",
    "# encoder\n",
    "encoder = Sequential([\n",
    "    Embedding(vocab_size+1, 32, input_length=fixed_length),\n",
    "    LSTM(32),\n",
    "    Dense(16, activation='relu')\n",
    "])\n",
    "\n",
    "# decoder\n",
    "decoder = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(16,)),\n",
    "    RepeatVector(fixed_length),\n",
    "    LSTM(32, return_sequences=True),\n",
    "    TimeDistributed(Dense(vocab_size+1, activation='softmax'))\n",
    "])\n",
    "\n",
    "# autoencoder\n",
    "autoencoder = Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "autoencoder.summary()\n",
    "\n",
    "# train autoencoder\n",
    "autoencoder.fit(X_train_vectorized, X_train_vectorized, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
