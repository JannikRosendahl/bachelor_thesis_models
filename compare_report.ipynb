{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_float(value):\n",
    "    # check for nan\n",
    "    if value != value:\n",
    "        return '   NaN'\n",
    "    return \"{:+.3f}\".format(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_1 = 'pioneer/saves/pioneer/'\n",
    "experiment_2 = 'pioneer/saves/pioneer_lstm/'\n",
    "\n",
    "report_path = 'classification_report.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load both dicts\n",
    "\n",
    "experiment_1_dict = json.load(open(experiment_1 + report_path))\n",
    "experiment_2_dict = json.load(open(experiment_2 + report_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare both dicts\n",
    "\n",
    "e1_m_precision = experiment_1_dict['macro avg']['precision']\n",
    "e1_m_recall = experiment_1_dict['macro avg']['recall']\n",
    "e1_m_f1 = experiment_1_dict['macro avg']['f1-score']\n",
    "e1_w_precision = experiment_1_dict['weighted avg']['precision']\n",
    "e1_w_recall = experiment_1_dict['weighted avg']['recall']\n",
    "e1_w_f1 = experiment_1_dict['weighted avg']['f1-score']\n",
    "\n",
    "e2_m_precision = experiment_2_dict['macro avg']['precision']\n",
    "e2_m_recall = experiment_2_dict['macro avg']['recall']\n",
    "e2_m_f1 = experiment_2_dict['macro avg']['f1-score']\n",
    "e2_w_precision = experiment_2_dict['weighted avg']['precision']\n",
    "e2_w_recall = experiment_2_dict['weighted avg']['recall']\n",
    "e2_w_f1 = experiment_2_dict['weighted avg']['f1-score']\n",
    "\n",
    "# remove macro avg, weighted avg and accuracy\n",
    "del experiment_1_dict['macro avg']\n",
    "del experiment_1_dict['weighted avg']\n",
    "del experiment_1_dict['accuracy']\n",
    "del experiment_2_dict['macro avg']\n",
    "del experiment_2_dict['weighted avg']\n",
    "del experiment_2_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Experiment 1 macro precision: +0.832\n",
      "Experiment 1 macro recall: +0.873\n",
      "Experiment 1 macro f1: +0.822\n",
      "Experiment 1 weighted precision: +0.982\n",
      "Experiment 1 weighted recall: +0.969\n",
      "Experiment 1 weighted f1: +0.974\n",
      "Experiment 2 macro precision: +0.856\n",
      "Experiment 2 macro recall: +0.890\n",
      "Experiment 2 macro f1: +0.825\n",
      "Experiment 2 weighted precision: +0.990\n",
      "Experiment 2 weighted recall: +0.969\n",
      "Experiment 2 weighted f1: +0.976\n"
     ]
    }
   ],
   "source": [
    "# print all metrics before and after\n",
    "print('Before:')\n",
    "print('Experiment 1 macro precision: ' + format_float(e1_m_precision))\n",
    "print('Experiment 1 macro recall: ' + format_float(e1_m_recall))\n",
    "print('Experiment 1 macro f1: ' + format_float(e1_m_f1))\n",
    "print('Experiment 1 weighted precision: ' + format_float(e1_w_precision))\n",
    "print('Experiment 1 weighted recall: ' + format_float(e1_w_recall))\n",
    "print('Experiment 1 weighted f1: ' + format_float(e1_w_f1))\n",
    "print('Experiment 2 macro precision: ' + format_float(e2_m_precision))\n",
    "print('Experiment 2 macro recall: ' + format_float(e2_m_recall))\n",
    "print('Experiment 2 macro f1: ' + format_float(e2_m_f1))\n",
    "print('Experiment 2 weighted precision: ' + format_float(e2_w_precision))\n",
    "print('Experiment 2 weighted recall: ' + format_float(e2_w_recall))\n",
    "print('Experiment 2 weighted f1: ' + format_float(e2_w_f1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro avg precision difference:     +0.023\n",
      "macro avg recall difference:        +0.017\n",
      "macro avg f1 difference:            +0.003\n",
      "\n",
      "weighted avg precision difference:  +0.008\n",
      "weighted avg recall difference:     +0.000\n",
      "weighted avg f1 difference:         +0.002\n"
     ]
    }
   ],
   "source": [
    "# print difference in metrics\n",
    "print(f'macro avg precision difference:     {e2_m_precision - e1_m_precision:+.3f}')\n",
    "print(f'macro avg recall difference:        {e2_m_recall - e1_m_recall:+.3f}')\n",
    "print(f'macro avg f1 difference:            {e2_m_f1 - e1_m_f1:+.3f}', end='\\n\\n')\n",
    "print(f'weighted avg precision difference:  {e2_w_precision - e1_w_precision:+.3f}')\n",
    "print(f'weighted avg recall difference:     {e2_w_recall - e1_w_recall:+.3f}')\n",
    "print(f'weighted avg f1 difference:         {e2_w_f1 - e1_w_f1:+.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dict with the difference in metrics\n",
    "diff_dict = {}\n",
    "for key in experiment_1_dict.keys():\n",
    "    diff_dict[key] = {}\n",
    "    for metric in experiment_1_dict[key].keys():\n",
    "        diff_dict[key][metric] = experiment_2_dict[key][metric] - experiment_1_dict[key][metric]\n",
    "\n",
    "# copy support metric from experiment 1\n",
    "for key in experiment_1_dict.keys():\n",
    "    diff_dict[key]['support'] = experiment_1_dict[key]['support']\n",
    "\n",
    "# sort by f1-score\n",
    "sorted_diff_dict = {k: v for k, v in sorted(diff_dict.items(), key=lambda item: item[1]['f1-score'], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by f1-score difference:\n",
      "mail:            precision: +0.333, recall: +0.500, f1-score: +0.400, support: 2.0\n",
      "cmp:             precision: +0.286, recall: +0.000, f1-score: +0.167, support: 5.0\n",
      "rm:              precision: +0.369, recall: +0.000, f1-score: +0.153, support: 36.0\n",
      "mount:           precision: +0.167, recall: +0.000, f1-score: +0.133, support: 2.0\n",
      "netstat:         precision: +0.182, recall: +0.000, f1-score: +0.093, support: 58.0\n",
      "awk:             precision: +0.167, recall: +0.000, f1-score: +0.091, support: 5.0\n",
      "trivial-rewrite: precision: +0.188, recall: +0.019, f1-score: +0.083, support: 377.0\n",
      "mktemp:          precision: +0.107, recall: +0.000, f1-score: +0.066, support: 6.0\n",
      "wget:            precision: +0.078, recall: +0.041, f1-score: +0.060, support: 74.0\n",
      "wc:              precision: +0.097, recall: +0.000, f1-score: +0.058, support: 7.0\n",
      "cleanup:         precision: +0.515, recall: -0.264, f1-score: +0.051, support: 276.0\n",
      "dhclient:        precision: +0.101, recall: +0.000, f1-score: +0.042, support: 17.0\n",
      "uptime:          precision: +0.067, recall: +0.000, f1-score: +0.034, support: 14.0\n",
      "alpine:          precision: +0.062, recall: -0.007, f1-score: +0.034, support: 560.0\n",
      "cat:             precision: +0.111, recall: -0.038, f1-score: +0.033, support: 26.0\n",
      "proxymap:        precision: +0.410, recall: -0.230, f1-score: +0.029, support: 331.0\n",
      "sed:             precision: +0.011, recall: +0.500, f1-score: +0.021, support: 2.0\n",
      "pickup:          precision: +0.017, recall: +0.007, f1-score: +0.011, support: 143.0\n",
      "dd:              precision: +0.008, recall: +0.000, f1-score: +0.004, support: 125.0\n",
      "sshd:            precision: +0.002, recall: +0.002, f1-score: +0.002, support: 427.0\n",
      "atrun:           precision: +0.004, recall: +0.000, f1-score: +0.002, support: 237.0\n",
      "top:             precision: +0.001, recall: +0.003, f1-score: +0.002, support: 1913.0\n",
      "smtpd:           precision: +0.001, recall: +0.002, f1-score: +0.002, support: 818.0\n",
      "sh:              precision: +0.009, recall: -0.005, f1-score: +0.002, support: 1987.0\n",
      "bash:            precision: +0.000, recall: +0.003, f1-score: +0.001, support: 12512.0\n",
      "find:            precision: +0.001, recall: +0.001, f1-score: +0.001, support: 4006.0\n",
      "anvil:           precision: -0.057, recall: +0.302, f1-score: +0.001, support: 378.0\n",
      "head:            precision: +0.001, recall: +0.000, f1-score: +0.000, support: 1219.0\n",
      "basename:        precision:    NaN, recall: +0.000, f1-score: +0.000, support: 2.0\n",
      "cp:              precision: +0.000, recall: +0.000, f1-score: +0.000, support: 30.0\n",
      "cron:            precision: +0.000, recall: +0.000, f1-score: +0.000, support: 624.0\n",
      "dmesg:           precision: +0.000, recall: +0.000, f1-score: +0.000, support: 15.0\n",
      "egrep:           precision: +0.000, recall: +0.000, f1-score: +0.000, support: 2.0\n",
      "expr:            precision:    NaN, recall: +0.000, f1-score: +0.000, support: 2.0\n",
      "fortune:         precision: +0.000, recall: +0.000, f1-score: +0.000, support: 91.0\n",
      "hostname:        precision: +0.000, recall: +0.000, f1-score: +0.000, support: 10.0\n",
      "inetd:           precision: +0.000, recall: +0.000, f1-score: +0.000, support: 291.0\n",
      "lsof:            precision: +0.000, recall: +0.000, f1-score: +0.000, support: 8568.0\n",
      "mailwrapper:     precision: +0.000, recall: +0.000, f1-score: +0.000, support: 3.0\n",
      "python2.7:       precision: +0.000, recall: +0.000, f1-score: +0.000, support: 841.0\n",
      "resizewin:       precision: +0.000, recall: +0.000, f1-score: +0.000, support: 91.0\n",
      "sleep:           precision: +0.000, recall: +0.000, f1-score: +0.000, support: 4889.0\n",
      "sysctl:          precision: +0.000, recall: +0.000, f1-score: +0.000, support: 129.0\n",
      "tty:             precision: +0.000, recall: +0.000, f1-score: +0.000, support: 2.0\n",
      "vmstat:          precision: +0.000, recall: +0.000, f1-score: +0.000, support: 2468.0\n",
      "mv:              precision: +0.001, recall: -0.001, f1-score: -0.000, support: 860.0\n",
      "imapd:           precision: +0.001, recall: -0.001, f1-score: -0.000, support: 2469.0\n",
      "local:           precision: -0.002, recall: +0.000, f1-score: -0.001, support: 868.0\n",
      "pkg:             precision: -0.000, recall: -0.001, f1-score: -0.001, support: 1701.0\n",
      "date:            precision: -0.001, recall: -0.001, f1-score: -0.001, support: 1218.0\n",
      "mlock:           precision: -0.004, recall: +0.000, f1-score: -0.002, support: 506.0\n",
      "unlink:          precision: -0.008, recall: +0.000, f1-score: -0.004, support: 123.0\n",
      "master:          precision: -0.008, recall: +0.000, f1-score: -0.005, support: 580.0\n",
      "sudo:            precision: -0.058, recall: +0.000, f1-score: -0.033, support: 26.0\n",
      "adjkerntz:       precision: -0.035, recall: +0.000, f1-score: -0.034, support: 11.0\n",
      "sendmail:        precision: -0.050, recall: -0.048, f1-score: -0.049, support: 21.0\n",
      "ps:              precision: -0.089, recall: +0.000, f1-score: -0.064, support: 5.0\n",
      "grep:            precision: +0.029, recall: -0.200, f1-score: -0.067, support: 5.0\n",
      "route:           precision: -0.125, recall: +0.000, f1-score: -0.067, support: 7.0\n",
      "lockf:           precision: -0.100, recall: +0.000, f1-score: -0.083, support: 3.0\n",
      "ls:              precision: -0.083, recall: -0.083, f1-score: -0.083, support: 12.0\n",
      "less:            precision: -0.054, recall: +0.667, f1-score: -0.088, support: 3.0\n",
      "mkdir:           precision: -0.182, recall: +0.000, f1-score: -0.100, support: 18.0\n",
      "newsyslog:       precision: -0.214, recall: +0.000, f1-score: -0.114, support: 18.0\n",
      "tee:             precision: -0.250, recall: +0.000, f1-score: -0.143, support: 6.0\n",
      "kill:            precision: -0.333, recall: +0.000, f1-score: -0.200, support: 2.0\n",
      "sort:            precision: -0.150, recall: +0.000, f1-score: -0.218, support: 1.0\n"
     ]
    }
   ],
   "source": [
    "# print sorted dict\n",
    "print('Sorted by f1-score difference:')\n",
    "for key in sorted_diff_dict.keys():\n",
    "    print(f'{(key + \":\").ljust(17)}precision: {format_float(sorted_diff_dict[key][\"precision\"])}, recall: {format_float(sorted_diff_dict[key][\"recall\"])}, f1-score: {format_float(sorted_diff_dict[key][\"f1-score\"])}, support: {sorted_diff_dict[key][\"support\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes never predicted in experiment 1:\n",
      "['basename', 'expr']\n",
      "Classes never predicted in experiment 2:\n",
      "['basename', 'expr']\n"
     ]
    }
   ],
   "source": [
    "# check which classes were never predicted in both experiments (precision NaN)\n",
    "e1_never_predicted = []\n",
    "e2_never_predicted = []\n",
    "\n",
    "for key in experiment_1_dict.keys():\n",
    "    if experiment_1_dict[key]['precision'] != experiment_1_dict[key]['precision']:\n",
    "        e1_never_predicted.append(key)\n",
    "    if experiment_2_dict[key]['precision'] != experiment_2_dict[key]['precision']:\n",
    "        e2_never_predicted.append(key)\n",
    "\n",
    "print('Classes never predicted in experiment 1:')\n",
    "print(e1_never_predicted)\n",
    "print('Classes never predicted in experiment 2:')\n",
    "print(e2_never_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
