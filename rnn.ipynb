{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.src.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.src.layers import SimpleRNN, LSTM, Dense, Dropout\n",
    "from keras import Sequential, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 sequences\n",
      "Loaded 100000 sequences\n",
      "Loaded 150000 sequences\n",
      "Loaded 200000 sequences\n",
      "Loaded 250000 sequences\n",
      "Loaded 300000 sequences\n",
      "Loaded 350000 sequences\n",
      "Loaded 400000 sequences\n",
      "Loaded 447415 sequences\n",
      "Found 1988 sequences longer than 1000\n",
      "Split them into 18540 sequences\n",
      "Filtered out datapoints with less than 10 occurrences\n",
      "Left with 447415 datapoints\n",
      "Found 135 distinct labels\n",
      "Found 29 distinct features\n",
      "Encoded labels to one-hot\n"
     ]
    }
   ],
   "source": [
    "data_directory = '/home/jrosendahl/datasets/cadets/sequences/'\n",
    "\n",
    "data = []\n",
    "\n",
    "labels = None\n",
    "no_labels = None\n",
    "\n",
    "distinct_features = [\n",
    "'EVENT_ACCEPT', 'EVENT_BIND', 'EVENT_CHANGE_PRINCIPAL', 'EVENT_CLOSE', 'EVENT_CONNECT', 'EVENT_CREATE_OBJECT', 'EVENT_EXECUTE', 'EVENT_EXIT', 'EVENT_FCNTL', 'EVENT_FORK', 'EVENT_LINK', 'EVENT_LOGIN', 'EVENT_LSEEK', 'EVENT_MMAP', 'EVENT_MODIFY_FILE_ATTRIBUTES', 'EVENT_MODIFY_PROCESS', 'EVENT_MPROTECT', 'EVENT_OPEN', 'EVENT_OTHER', 'EVENT_READ', 'EVENT_RECVFROM', 'EVENT_RECVMSG', 'EVENT_RENAME', 'EVENT_SENDMSG', 'EVENT_SENDTO', 'EVENT_SIGNAL', 'EVENT_TRUNCATE', 'EVENT_UNLINK', 'EVENT_WRITE', \n",
    "]\n",
    "distinct_features = [ x[6:] for x in distinct_features ]\n",
    "no_features = len(distinct_features)\n",
    "\n",
    "count = 0\n",
    "count_long_sequences_splitted = 0\n",
    "count_long_sequences_splitted_result = 0\n",
    "for file_name in os.listdir(data_directory):\n",
    "    count += 1\n",
    "    if count % 50000 == 0:\n",
    "        print(f'Loaded {count} sequences')\n",
    "    with open(data_directory + file_name, 'r') as f:\n",
    "        label = file_name.split('_')[0]\n",
    "        # build dictionary with counts of events\n",
    "        lines = f.readlines()\n",
    "        # if sequence is longer than 1000, split into multiple sequences\n",
    "        if len(lines) > 1000:\n",
    "            count_long_sequences_splitted += 1\n",
    "            for i in range(0, len(lines), 1000):\n",
    "                count_long_sequences_splitted_result += 1\n",
    "                datapoints = []\n",
    "                for event in lines[i:i+1000]:\n",
    "                    event = event.strip()\n",
    "                    datapoints.append(distinct_features.index(event))\n",
    "                data.append((label, datapoints))\n",
    "        else:\n",
    "            datapoints = []\n",
    "            for event in lines:\n",
    "                event = event.strip()\n",
    "                datapoints.append(distinct_features.index(event))\n",
    "            data.append((label, datapoints))\n",
    "\n",
    "        \"\"\"\n",
    "        datapoints = []\n",
    "        for event in f:\n",
    "            event = event.strip()\n",
    "            datapoints.append(distinct_features.index(event))\n",
    "        if not len(datapoints) > 1000:\n",
    "            data.append((label, datapoints))\n",
    "        \"\"\"\n",
    "\n",
    "print(f'Loaded {len(data)} sequences')\n",
    "print(f'Found {count_long_sequences_splitted} sequences longer than 1000')\n",
    "print(f'Split them into {count_long_sequences_splitted_result} sequences')\n",
    "\n",
    "print(f'Filtered out datapoints with less than 10 occurrences')\n",
    "print(f'Left with {len(data)} datapoints')\n",
    "\n",
    "random.shuffle(data)\n",
    "labels = [ x[0] for x in data ]\n",
    "data = [ x[1] for x in data ]\n",
    "\n",
    "distinct_labels = np.unique(np.array(labels))\n",
    "no_labels = len(distinct_labels)\n",
    "print(f'Found {no_labels} distinct labels')\n",
    "\n",
    "# get distinct features\n",
    "print(f'Found {no_features} distinct features')\n",
    "\n",
    "# encode labels from strings to integers to one-hot\n",
    "labels = np.eye(no_labels)[np.vectorize(distinct_labels.tolist().index)(labels)]\n",
    "print(f'Encoded labels to one-hot')\n",
    "\n",
    "# encode sequences from list of integers to list of one-hot\n",
    "data = [ np.eye(no_features)[x] for x in data ]\n",
    "\n",
    "# get pad event to pad sequences with when batches are built\n",
    "pad_event = np.zeros(no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 447415\n",
      "labels shape: (447415, 135)\n"
     ]
    }
   ],
   "source": [
    "print(f'data length: {len(data)}')\n",
    "print(f'labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data + generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 357932 samples\n",
      "Validating on 89483 samples\n"
     ]
    }
   ],
   "source": [
    "# split data into training and validation\n",
    "split = int(len(data) * 0.8)\n",
    "\n",
    "X_train = data[:split]\n",
    "y_train = np.array(labels[:split])\n",
    "\n",
    "X_val = data[split:]\n",
    "y_val = np.array(labels[split:])\n",
    "\n",
    "print(f'Training on {len(X_train)} samples')\n",
    "print(f'Validating on {len(X_val)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        # valid **kwargs: workers, use_multiprocessing, max_queue_size\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.no_samples = len(X)\n",
    "        self.no_batches = int(np.ceil(self.no_samples / self.batch_size))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.no_batches\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = min(start + self.batch_size, self.no_samples)\n",
    "        X_batch = self.X[start:end]\n",
    "        y_batch = self.y[start:end]\n",
    "        max_len = max([ len(x) for x in X_batch ])\n",
    "        X_batch = [ np.pad(x, ((0, max_len - len(x)), (0, 0)), 'constant', constant_values=0) for x in X_batch ]\n",
    "        return np.array(X_batch), np.array(y_batch)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,016</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,775</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_12 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,016\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_13 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_14 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m135\u001b[0m)            │         \u001b[38;5;34m8,775\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,303</span> (122.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,303\u001b[0m (122.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,303</span> (122.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,303\u001b[0m (122.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential(layers=[\n",
    "    Input(shape=(None, no_features)),\n",
    "    SimpleRNN(64, return_sequences=True),\n",
    "    SimpleRNN(64, return_sequences=True),\n",
    "    SimpleRNN(64, return_sequences=False),\n",
    "    Dense(no_labels, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "checkpoint_path = (\"/home/jrosendahl/sync/models/checkpoints\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f'{checkpoint_path}/rnn_simple.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_schedule = ReduceLROnPlateau(\n",
    "    monitor='loss', \n",
    "    factor=0.1, \n",
    "    patience=3, \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(\n",
    "    filename=f'{checkpoint_path}/rnn.log',\n",
    "    append=True\n",
    ")\n",
    "\n",
    "\n",
    "# 'categorical_focal_crossentropy'\n",
    "# 'categorical_crossentropy'\n",
    "model.compile(optimizer='adam', loss='categorical_focal_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrosendahl/.virtualenvs/models/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1064/5593\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:06\u001b[0m 266ms/step - accuracy: 0.3385 - loss: 0.6038"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=Generator(X_train, y_train, 64),\n",
    "    validation_data=Generator(X_val, y_val, 32),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, model_checkpoint, lr_schedule, csv_logger],\n",
    ")\n",
    "\n",
    "# save history to file\n",
    "with open(f'{checkpoint_path}/rnn_history.npy', 'wb') as f:\n",
    "    np.save(f, history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
